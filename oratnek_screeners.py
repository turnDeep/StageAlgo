"""
Oratnekå¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
IBD (Investor's Business Daily) æ‰‹æ³•ã«åŸºã¥ã6ã¤ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒªã‚¹ãƒˆ

å®Ÿè£…ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼:
1. Momentum 97 - 1M/3M/6Mã™ã¹ã¦ã§ä¸Šä½3%
2. Explosive EPS Growth - ä»Šå››åŠæœŸEPSäºˆæƒ³ãŒ100%ä»¥ä¸Šæˆé•·
3. Up on Volume - å‡ºæ¥é«˜ã‚’ä¼´ã£ã¦ä¸Šæ˜‡ã—ã¦ã„ã‚‹æ©Ÿé–¢æŠ•è³‡å®¶æ³¨ç›®éŠ˜æŸ„
4. Top 2% RS Rating - RS Ratingä¸Šä½2%ã‹ã¤ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå®Œç’§
5. 4% Bullish Yesterday - æ˜¨æ—¥4%ä»¥ä¸Šä¸Šæ˜‡
6. Healthy Chart Watch List - å¥å…¨ãªãƒãƒ£ãƒ¼ãƒˆå½¢çŠ¶ã‚’æŒã¤é«˜å“è³ªéŠ˜æŸ„

SQLiteãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã¨ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹åŒ–ã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã€‚
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
import concurrent.futures
import logging
from tqdm import tqdm

from oratnek_data_manager import OratnekDataManager
from indicators import calculate_all_basic_indicators
from rs_calculator import RSCalculator

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹è¨­å®š
MAX_WORKERS = int(os.getenv('ORATNEK_MAX_WORKERS', '10'))
BATCH_SIZE = int(os.getenv('ORATNEK_BATCH_SIZE', '50'))


class IBDIndicators:
    """
    IBD (Investor's Business Daily) å¼æŒ‡æ¨™è¨ˆç®—ã‚¯ãƒ©ã‚¹

    è¨ˆç®—ã™ã‚‹æŒ‡æ¨™:
    - RS Rating: ç›¸å¯¾çš„å¼·ã•ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (1-99)
    - A/D Rating: æ©Ÿé–¢æŠ•è³‡å®¶ã®è“„ç©/åˆ†æ•£è©•ä¾¡ (A-E)
    - Comp Rating: ç·åˆãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (1-99)
    - EPS Rating: EPSæˆé•·ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    """

    @staticmethod
    def calculate_rs_rating(df: pd.DataFrame, benchmark_df: pd.DataFrame) -> float:
        """
        IBDå¼ RS Ratingè¨ˆç®—

        åŠ é‡å¹³å‡:
        - 40% Ã— ç›´è¿‘3ãƒ¶æœˆï¼ˆ63æ—¥ï¼‰
        - 20% Ã— ç›´è¿‘6ãƒ¶æœˆï¼ˆ126æ—¥ï¼‰
        - 20% Ã— ç›´è¿‘9ãƒ¶æœˆï¼ˆ189æ—¥ï¼‰
        - 20% Ã— ç›´è¿‘12ãƒ¶æœˆï¼ˆ252æ—¥ï¼‰

        Returns:
            RS Rating (0-100ã‚¹ã‚±ãƒ¼ãƒ«)
        """
        if len(df) < 252:
            return 50.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        try:
            rs_calc = RSCalculator(df, benchmark_df)
            rs_score_series = rs_calc.calculate_ibd_rs_score()

            if len(rs_score_series) > 0:
                # æœ€æ–°ã®RSã‚¹ã‚³ã‚¢ã‚’å–å¾—ã—ã€0-100ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                rs_score = rs_score_series.iloc[-1]
                # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                return min(100, max(0, rs_score + 50))  # ä¸­å¿ƒã‚’50ã«èª¿æ•´

            return 50.0
        except Exception as e:
            print(f"RS Rating calculation error: {e}")
            return 50.0

    @staticmethod
    def calculate_ad_rating(df: pd.DataFrame, lookback: int = 13) -> str:
        """
        A/D Rating (Accumulation/Distribution) è¨ˆç®—

        æ©Ÿé–¢æŠ•è³‡å®¶ã®è“„ç©/åˆ†æ•£ã‚’è©•ä¾¡

        Args:
            df: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿
            lookback: è©•ä¾¡æœŸé–“ï¼ˆé€±ï¼‰

        Returns:
            A/D Rating: 'A' (å¼·ã„è“„ç©) ~ 'E' (å¼·ã„åˆ†æ•£)
        """
        if len(df) < lookback:
            return 'C'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸­ç«‹

        try:
            # ç›´è¿‘lookbacké€±ã®ãƒ‡ãƒ¼ã‚¿
            recent_data = df.tail(lookback * 5)  # é€± â†’ å–¶æ¥­æ—¥å¤‰æ›ï¼ˆæ¦‚ç®—ï¼‰

            ad_value = 0

            for i in range(1, len(recent_data)):
                price_change = recent_data['Close'].iloc[i] - recent_data['Close'].iloc[i-1]
                volume = recent_data['Volume'].iloc[i]

                if price_change > 0:
                    # ä¸Šæ˜‡æ—¥: å‡ºæ¥é«˜ã‚’ãƒ—ãƒ©ã‚¹
                    ad_value += volume
                elif price_change < 0:
                    # ä¸‹è½æ—¥: å‡ºæ¥é«˜ã‚’ãƒã‚¤ãƒŠã‚¹
                    ad_value -= volume

            # å¹³å‡å‡ºæ¥é«˜ã§æ­£è¦åŒ–
            avg_volume = recent_data['Volume'].mean()
            if avg_volume > 0:
                normalized_ad = ad_value / (avg_volume * len(recent_data))
            else:
                normalized_ad = 0

            # A/D Ratingã«å¤‰æ›
            if normalized_ad > 0.5:
                return 'A'  # éå¸¸ã«å¼·ã„è“„ç©
            elif normalized_ad > 0.2:
                return 'B'  # è“„ç©
            elif normalized_ad > -0.2:
                return 'C'  # ä¸­ç«‹
            elif normalized_ad > -0.5:
                return 'D'  # åˆ†æ•£
            else:
                return 'E'  # éå¸¸ã«å¼·ã„åˆ†æ•£

        except Exception as e:
            print(f"A/D Rating calculation error: {e}")
            return 'C'

    @staticmethod
    def calculate_comp_rating(rs_rating: float, eps_rating: float = 50.0) -> float:
        """
        Comp Rating (Composite Rating) è¨ˆç®—

        Args:
            rs_rating: RS Rating (0-100)
            eps_rating: EPS Rating (0-100) - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50

        Returns:
            Composite Rating (0-100)
        """
        # EPSã¨RSã®åŠ é‡å¹³å‡ï¼ˆRSã‚’ã‚„ã‚„é‡è¦–ï¼‰
        comp_rating = (rs_rating * 0.6 + eps_rating * 0.4)
        return min(100, max(0, comp_rating))

    @staticmethod
    def calculate_relative_volume(df: pd.DataFrame, days: int = 50) -> float:
        """
        ç›¸å¯¾å‡ºæ¥é«˜ã‚’è¨ˆç®—

        Args:
            df: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿
            days: å¹³å‡å‡ºæ¥é«˜ã®è¨ˆç®—æœŸé–“

        Returns:
            ç›¸å¯¾å‡ºæ¥é«˜ (current_volume / avg_volume)
        """
        if len(df) < days:
            return 1.0

        try:
            current_volume = df['Volume'].iloc[-1]
            avg_volume = df['Volume'].tail(days).mean()

            if avg_volume > 0:
                return current_volume / avg_volume
            return 1.0
        except:
            return 1.0


class OratnekScreener:
    """
    Oratnekãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

    6ã¤ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’æä¾›:
    1. Momentum 97
    2. Explosive EPS Growth
    3. Up on Volume
    4. Top 2% RS Rating
    5. 4% Bullish Yesterday
    6. Healthy Chart Watch List
    """

    def __init__(self, tickers: List[str], data_manager: Optional[OratnekDataManager] = None):
        """
        Args:
            tickers: ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆ
            data_manager: ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆNoneã®å ´åˆã¯æ–°è¦ä½œæˆï¼‰
        """
        self.tickers = tickers
        self.data_manager = data_manager or OratnekDataManager()
        self.data_cache = {}
        self.benchmark_data = None
        self.industry_rs_cache = {}  # Industry Group RSã‚­ãƒ£ãƒƒã‚·ãƒ¥

        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆSPYï¼‰ã‚’å–å¾—
        self._load_benchmark()

    def _load_benchmark(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆSPYï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            logger.info("Loading SPY benchmark data...")
            result = self.data_manager.get_stock_data_with_cache('SPY', lookback_years=10)
            if result:
                spy_df, _ = result
                if spy_df is not None and not spy_df.empty:
                    # åˆ—åã‚’å¤§æ–‡å­—ã«å¤‰æ›ï¼ˆindicators.pyã¨ã®äº’æ›æ€§ï¼‰
                    spy_df_upper = spy_df.copy()
                    spy_df_upper.columns = [col.capitalize() for col in spy_df_upper.columns]
                    self.benchmark_data = spy_df_upper
                    logger.info(f"Benchmark loaded: {len(self.benchmark_data)} days")
                else:
                    logger.warning("Warning: Could not load SPY benchmark data")
            else:
                logger.warning("Warning: SPY data not available")
        except Exception as e:
            logger.error(f"Error loading benchmark: {e}", exc_info=True)

    def calculate_industry_group_rs(self) -> Dict[str, str]:
        """
        å„æ¥­ç¨®ï¼ˆIndustryï¼‰ã®Relative Strengthã‚’è¨ˆç®—ã—ã€A/B/C/D/Eã§è©•ä¾¡

        Returns:
            {industry_name: 'A'|'B'|'C'|'D'|'E'} ã®è¾æ›¸
        """
        if self.industry_rs_cache:
            return self.industry_rs_cache

        logger.info("Calculating Industry Group RS...")

        industry_performance = {}

        # å„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®æ¥­ç¨®ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åé›†
        for ticker in tqdm(self.tickers, desc="Industry RSè¨ˆç®—ä¸­", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data
            industry = metrics.get('industry', '').strip()

            if not industry or industry == '':
                continue

            # æ¥­ç¨®ã”ã¨ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’é›†è¨ˆï¼ˆ3ãƒ¶æœˆãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼‰
            returns_3m = metrics.get('returns_3m', 0)

            if industry not in industry_performance:
                industry_performance[industry] = []

            industry_performance[industry].append(returns_3m)

        # å„æ¥­ç¨®ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
        industry_avg_returns = {}
        for industry, returns_list in industry_performance.items():
            if len(returns_list) > 0:
                industry_avg_returns[industry] = np.mean(returns_list)

        if not industry_avg_returns:
            logger.warning("No industry performance data available")
            return {}

        # æ¥­ç¨®ã‚’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        sorted_industries = sorted(
            industry_avg_returns.items(),
            key=lambda x: x[1],
            reverse=True
        )

        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§A/B/C/D/Eã«åˆ†é¡
        total_industries = len(sorted_industries)
        industry_ratings = {}

        for i, (industry, _) in enumerate(sorted_industries):
            percentile = (i / total_industries) * 100

            if percentile <= 20:
                rating = 'A'  # ä¸Šä½20%
            elif percentile <= 40:
                rating = 'B'  # ä¸Šä½40%
            elif percentile <= 60:
                rating = 'C'  # ä¸­ä½60%
            elif percentile <= 80:
                rating = 'D'  # ä¸‹ä½80%
            else:
                rating = 'E'  # ä¸‹ä½20%

            industry_ratings[industry] = rating

        logger.info(f"Calculated RS ratings for {len(industry_ratings)} industries")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.industry_rs_cache = industry_ratings

        return industry_ratings

    def _get_stock_data(self, ticker: str) -> Optional[Tuple[pd.DataFrame, Dict]]:
        """
        æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã¨åŸºæœ¬æŒ‡æ¨™ã‚’å–å¾—ï¼ˆSQLiteã‹ã‚‰ï¼‰

        Returns:
            (indicators_df, metrics_dict) or None
        """
        if ticker in self.data_cache:
            return self.data_cache[ticker]

        try:
            # SQLiteã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
            result = self.data_manager.get_stock_data_with_cache(ticker, lookback_years=2)
            if result is None:
                return None

            df, _ = result
            if df is None or len(df) < 100:
                return None

            # åˆ—åã‚’å¤§æ–‡å­—ã«å¤‰æ›ï¼ˆindicators.pyã¨ã®äº’æ›æ€§ï¼‰
            df_upper = df.copy()
            df_upper.columns = [col.capitalize() if col.lower() in ['open', 'high', 'low', 'close', 'volume'] else col for col in df_upper.columns]

            # ç§»å‹•å¹³å‡ã¯æ—¢ã«SQLiteã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãŒã€indicators.pyã®ä»–ã®æŒ‡æ¨™ã‚‚è¿½åŠ 
            indicators_df = calculate_all_basic_indicators(df_upper)

            if len(indicators_df) < 100:
                return None

            latest = indicators_df.iloc[-1]

            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            metrics = {
                'ticker': ticker,
                'price': latest['Close'],
                'volume': latest['Volume'],
                'avg_volume_50d': indicators_df['Volume'].tail(50).mean(),
                'avg_volume_90d': indicators_df['Volume'].tail(90).mean(),
                'sma_10': latest.get('SMA_10', latest.get('sma_10', 0)),
                'sma_21': latest.get('SMA_21', latest.get('sma_21', 0)),
                'sma_50': latest.get('SMA_50', latest.get('sma_50', 0)),
                'sma_150': latest.get('SMA_150', latest.get('sma_150', 0)),
                'sma_200': latest.get('SMA_200', latest.get('sma_200', 0)),
            }

            # RS Ratingè¨ˆç®—
            if self.benchmark_data is not None:
                metrics['rs_rating'] = IBDIndicators.calculate_rs_rating(
                    indicators_df, self.benchmark_data
                )
            else:
                metrics['rs_rating'] = 50.0

            # A/D Ratingè¨ˆç®—
            metrics['ad_rating'] = IBDIndicators.calculate_ad_rating(indicators_df)

            # Comp Ratingè¨ˆç®—
            metrics['comp_rating'] = IBDIndicators.calculate_comp_rating(
                metrics['rs_rating']
            )

            # ç›¸å¯¾å‡ºæ¥é«˜
            metrics['rel_volume'] = IBDIndicators.calculate_relative_volume(indicators_df)

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
            if len(indicators_df) >= 252:
                metrics['returns_1m'] = ((latest['Close'] / indicators_df['Close'].iloc[-21] - 1) * 100)
                metrics['returns_3m'] = ((latest['Close'] / indicators_df['Close'].iloc[-63] - 1) * 100)
                metrics['returns_6m'] = ((latest['Close'] / indicators_df['Close'].iloc[-126] - 1) * 100)
                metrics['returns_1y'] = ((latest['Close'] / indicators_df['Close'].iloc[-252] - 1) * 100)
            else:
                metrics['returns_1m'] = 0
                metrics['returns_3m'] = 0
                metrics['returns_6m'] = 0
                metrics['returns_1y'] = 0

            # æ—¥æ¬¡å¤‰åŒ–ç‡
            if len(indicators_df) >= 2:
                prev_close = indicators_df['Close'].iloc[-2]
                metrics['price_change_pct'] = ((latest['Close'] - prev_close) / prev_close) * 100

                # å¯„ã‚Šé«˜ã‹ã‚‰ã®å¤‰åŒ–
                if 'Open' in indicators_df.columns:
                    today_open = latest.get('Open', latest['Close'])
                    metrics['change_from_open_pct'] = ((latest['Close'] - today_open) / today_open) * 100
                else:
                    metrics['change_from_open_pct'] = 0
            else:
                metrics['price_change_pct'] = 0
                metrics['change_from_open_pct'] = 0

            # å‡ºæ¥é«˜å¤‰åŒ–ç‡
            if metrics['avg_volume_50d'] > 0:
                metrics['vol_change_pct'] = ((metrics['volume'] / metrics['avg_volume_50d'] - 1) * 100)
            else:
                metrics['vol_change_pct'] = 0

            # RS Lineæ–°é«˜å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            metrics['rs_line_new_high'] = (metrics['rs_rating'] >= 90)

            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå¸‚å ´ã‚­ãƒ£ãƒƒãƒ—ã€ã‚»ã‚¯ã‚¿ãƒ¼ã€EPSæˆé•·ç‡ï¼‰ã‚’è¿½åŠ 
            fundamental_data = self.data_manager.get_fundamental_data(ticker)
            if fundamental_data:
                # å¸‚å ´ã‚­ãƒ£ãƒƒãƒ—ï¼ˆå˜ä½: millionï¼‰
                market_cap = fundamental_data.get('market_cap')
                metrics['market_cap'] = market_cap / 1_000_000 if market_cap else 0

                # ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±
                metrics['sector'] = fundamental_data.get('sector', '')
                metrics['industry'] = fundamental_data.get('industry', '')

                # EPSæˆé•·ç‡
                metrics['eps_growth_last_qtr'] = fundamental_data.get('eps_growth_last_qtr', 0) or 0
                metrics['eps_est_cur_qtr_growth'] = fundamental_data.get('eps_est_cur_qtr_growth', 0) or 0
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                metrics['market_cap'] = 0
                metrics['sector'] = ''
                metrics['industry'] = ''
                metrics['eps_growth_last_qtr'] = 0
                metrics['eps_est_cur_qtr_growth'] = 0

            # Industry Group RSï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ï¼‰
            industry = metrics['industry']
            if industry and self.industry_rs_cache:
                metrics['industry_group_rs'] = self.industry_rs_cache.get(industry, 'C')
            else:
                metrics['industry_group_rs'] = 'C'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸­ç«‹

            result = (indicators_df, metrics)
            self.data_cache[ticker] = result

            return result

        except Exception as e:
            logger.error(f"Error processing {ticker}: {e}", exc_info=True)
            return None

    def screen_momentum_97(self) -> pd.DataFrame:
        """
        Momentum 97ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - 1M, 3M, 6M ã™ã¹ã¦ã§ä¸Šä½3% (â‰¥97ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«)

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[Momentum 97] Screening...")

        for ticker in tqdm(self.tickers, desc="ğŸš€ Momentum 97", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data

            results.append({
                'ticker': ticker,
                'returns_1m': metrics['returns_1m'],
                'returns_3m': metrics['returns_3m'],
                'returns_6m': metrics['returns_6m'],
            })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)

        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨ˆç®—
        df['rank_1m_pct'] = df['returns_1m'].rank(pct=True) * 100
        df['rank_3m_pct'] = df['returns_3m'].rank(pct=True) * 100
        df['rank_6m_pct'] = df['returns_6m'].rank(pct=True) * 100

        # ã™ã¹ã¦ã®æœŸé–“ã§97%ä»¥ä¸Š
        momentum_97 = df[
            (df['rank_1m_pct'] >= 97) &
            (df['rank_3m_pct'] >= 97) &
            (df['rank_6m_pct'] >= 97)
        ].copy()

        # ã‚½ãƒ¼ãƒˆ
        momentum_97 = momentum_97.sort_values('returns_1m', ascending=False)

        logger.info(f"  â†’ Found {len(momentum_97)} stocks")

        return momentum_97

    def screen_explosive_eps_growth(self) -> pd.DataFrame:
        """
        Explosive EPS Growth ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - RS Rating â‰¥ 80
        - EPSæˆé•·äºˆæƒ³ â‰¥ 100% (ä»Šå››åŠæœŸäºˆæƒ³YoYæˆé•·ç‡)
        - 50æ—¥å¹³å‡å‡ºæ¥é«˜ â‰¥ 100,000
        - ä¾¡æ ¼ â‰¥ 50æ—¥ç§»å‹•å¹³å‡

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[Explosive EPS Growth] Screening...")

        for ticker in tqdm(self.tickers, desc="ğŸ’¥ Explosive EPS", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶
            # EPSäºˆæƒ³æˆé•·ç‡ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°RS Ratingã®ã¿ã§åˆ¤å®š
            eps_growth_ok = (metrics['eps_est_cur_qtr_growth'] >= 100) if metrics['eps_est_cur_qtr_growth'] else True

            if (metrics['rs_rating'] >= 80 and
                eps_growth_ok and
                metrics['avg_volume_50d'] >= 100_000 and
                metrics['price'] >= metrics['sma_50']):

                results.append({
                    'ticker': ticker,
                    'price': metrics['price'],
                    'rs_rating': metrics['rs_rating'],
                    'eps_est_cur_qtr_growth': metrics['eps_est_cur_qtr_growth'],
                    'avg_volume_50d': metrics['avg_volume_50d'],
                    'price_vs_sma50_pct': ((metrics['price'] / metrics['sma_50'] - 1) * 100) if metrics['sma_50'] > 0 else 0,
                })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        df = df.sort_values('eps_est_cur_qtr_growth', ascending=False)

        logger.info(f"  â†’ Found {len(df)} stocks")

        return df

    def screen_up_on_volume(self) -> pd.DataFrame:
        """
        Up on Volume ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - å½“æ—¥ä¸Šæ˜‡ (â‰¥ 0%)
        - å‡ºæ¥é«˜ãŒ50æ—¥å¹³å‡ã®120%ä»¥ä¸Š
        - ä¾¡æ ¼ â‰¥ $10
        - 50æ—¥å¹³å‡å‡ºæ¥é«˜ â‰¥ 100,000
        - æ™‚ä¾¡ç·é¡ â‰¥ $250M
        - RS Rating â‰¥ 80
        - EPSæˆé•·ç‡ï¼ˆç›´è¿‘å››åŠæœŸï¼‰ â‰¥ 20%
        - A/D Rating: A, B, or C

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[Up on Volume] Screening...")

        for ticker in tqdm(self.tickers, desc="ğŸ“ˆ Up on Volume", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶
            if (metrics['price_change_pct'] >= 0 and
                metrics['vol_change_pct'] >= 20 and  # 120%ä»¥ä¸Š
                metrics['price'] >= 10 and
                metrics['avg_volume_50d'] >= 100_000 and
                metrics['market_cap'] >= 250 and  # $250Mä»¥ä¸Š
                metrics['rs_rating'] >= 80 and
                metrics['eps_growth_last_qtr'] >= 20 and  # EPSæˆé•·ç‡ â‰¥ 20%
                metrics['ad_rating'] in ['A', 'B', 'C']):

                results.append({
                    'ticker': ticker,
                    'price': metrics['price'],
                    'price_change_pct': metrics['price_change_pct'],
                    'vol_change_pct': metrics['vol_change_pct'],
                    'market_cap': metrics['market_cap'],
                    'eps_growth_last_qtr': metrics['eps_growth_last_qtr'],
                    'rs_rating': metrics['rs_rating'],
                    'ad_rating': metrics['ad_rating'],
                    'avg_volume_50d': metrics['avg_volume_50d'],
                })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        df = df.sort_values('vol_change_pct', ascending=False)

        logger.info(f"  â†’ Found {len(df)} stocks")

        return df

    def screen_top_2_percent_rs(self) -> pd.DataFrame:
        """
        Top 2% RS Rating ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - RS Rating â‰¥ 98 (ä¸Šä½2%)
        - MAé †åº: 10æ—¥ > 21æ—¥ > 50æ—¥
        - 50æ—¥å¹³å‡å‡ºæ¥é«˜ â‰¥ 100,000
        - å½“æ—¥å‡ºæ¥é«˜ â‰¥ 100,000
        - ã‚»ã‚¯ã‚¿ãƒ¼é™¤å¤–: Healthcare/Medical

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[Top 2% RS Rating] Screening...")

        for ticker in tqdm(self.tickers, desc="â­ Top 2% RS", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data

            # ã‚»ã‚¯ã‚¿ãƒ¼é™¤å¤–: Healthcare/Medical
            sector_lower = metrics.get('sector', '').lower()
            if 'health' in sector_lower or 'medical' in sector_lower:
                continue

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶
            if (metrics['rs_rating'] >= 98 and
                metrics['sma_10'] > metrics['sma_21'] and
                metrics['sma_21'] > metrics['sma_50'] and
                metrics['avg_volume_50d'] >= 100_000 and
                metrics['volume'] >= 100_000):

                results.append({
                    'ticker': ticker,
                    'price': metrics['price'],
                    'rs_rating': metrics['rs_rating'],
                    'sector': metrics['sector'],
                    'sma_10': metrics['sma_10'],
                    'sma_21': metrics['sma_21'],
                    'sma_50': metrics['sma_50'],
                    'avg_volume_50d': metrics['avg_volume_50d'],
                })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        df = df.sort_values('rs_rating', ascending=False)

        logger.info(f"  â†’ Found {len(df)} stocks")

        return df

    def screen_4_percent_bullish_yesterday(self) -> pd.DataFrame:
        """
        4% Bullish Yesterday ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - æ˜¨æ—¥4%ä»¥ä¸Šä¸Šæ˜‡
        - ä¾¡æ ¼ â‰¥ $1
        - æ™‚ä¾¡ç·é¡ > $250M
        - å‡ºæ¥é«˜ > 100K
        - ç›¸å¯¾å‡ºæ¥é«˜ > 1.0
        - å¯„ã‚Šé«˜ã‹ã‚‰æ›´ã«ä¸Šæ˜‡
        - 90æ—¥å¹³å‡å‡ºæ¥é«˜ > 100,000

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[4% Bullish Yesterday] Screening...")

        for ticker in tqdm(self.tickers, desc="ğŸ“Š 4% Bullish", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            indicators_df, metrics = data

            # æ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            if len(indicators_df) < 3:
                continue

            yesterday = indicators_df.iloc[-2]
            day_before = indicators_df.iloc[-3]

            yesterday_change = ((yesterday['Close'] - day_before['Close']) / day_before['Close']) * 100

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶
            if (yesterday_change > 4.0 and
                metrics['price'] >= 1.0 and
                metrics['market_cap'] > 250 and  # $250Mä»¥ä¸Š
                metrics['volume'] > 100_000 and  # å½“æ—¥å‡ºæ¥é«˜ > 100K
                metrics['rel_volume'] > 1.0 and
                metrics['change_from_open_pct'] > 0 and
                metrics['avg_volume_90d'] > 100_000):

                results.append({
                    'ticker': ticker,
                    'price': metrics['price'],
                    'market_cap': metrics['market_cap'],
                    'yesterday_change_pct': yesterday_change,
                    'volume': metrics['volume'],
                    'rel_volume': metrics['rel_volume'],
                    'change_from_open_pct': metrics['change_from_open_pct'],
                    'avg_volume_90d': metrics['avg_volume_90d'],
                })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        df = df.sort_values('yesterday_change_pct', ascending=False)

        logger.info(f"  â†’ Found {len(df)} stocks")

        return df

    def screen_healthy_chart_watchlist(self) -> pd.DataFrame:
        """
        Healthy Chart Watch List ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

        æ¡ä»¶:
        - çŸ­æœŸMAé †åº: 10æ—¥ > 21æ—¥ > 50æ—¥
        - é•·æœŸMAé †åº: 50æ—¥ > 150æ—¥ > 200æ—¥ (Stage 2ç¢ºèª)
        - RS Lineæ–°é«˜å€¤
        - RS Rating â‰¥ 90 (ä¸Šä½10%)
        - A/D Rating: A or B
        - Industry Group RS: A or B
        - Comp Rating â‰¥ 80
        - 50æ—¥å¹³å‡å‡ºæ¥é«˜ â‰¥ 100,000

        Returns:
            è©²å½“éŠ˜æŸ„ã®DataFrame
        """
        results = []

        logger.info("\n[Healthy Chart Watch List] Screening...")

        # Industry Group RSã‚’äº‹å‰è¨ˆç®—ï¼ˆåˆå›ã®ã¿ï¼‰
        if not self.industry_rs_cache:
            self.calculate_industry_group_rs()

        for ticker in tqdm(self.tickers, desc="ğŸ’š Healthy Chart", unit="ticker"):
            data = self._get_stock_data(ticker)
            if data is None:
                continue

            _, metrics = data

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶
            if (metrics['sma_10'] > metrics['sma_21'] and
                metrics['sma_21'] > metrics['sma_50'] and
                metrics['sma_50'] > metrics['sma_150'] and
                metrics['sma_150'] > metrics['sma_200'] and
                metrics['rs_line_new_high'] and
                metrics['rs_rating'] >= 90 and
                metrics['ad_rating'] in ['A', 'B'] and
                metrics['industry_group_rs'] in ['A', 'B'] and  # Industry Group RSè¿½åŠ 
                metrics['comp_rating'] >= 80 and
                metrics['avg_volume_50d'] >= 100_000):

                results.append({
                    'ticker': ticker,
                    'price': metrics['price'],
                    'rs_rating': metrics['rs_rating'],
                    'ad_rating': metrics['ad_rating'],
                    'industry': metrics['industry'],
                    'industry_group_rs': metrics['industry_group_rs'],
                    'comp_rating': metrics['comp_rating'],
                    'sma_50': metrics['sma_50'],
                    'sma_150': metrics['sma_150'],
                    'sma_200': metrics['sma_200'],
                    'avg_volume_50d': metrics['avg_volume_50d'],
                })

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        df = df.sort_values('comp_rating', ascending=False)

        logger.info(f"  â†’ Found {len(df)} stocks")

        return df

    def run_all_screens(self, use_multiprocessing: bool = True) -> Dict[str, pd.DataFrame]:
        """
        å…¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ

        Args:
            use_multiprocessing: ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã‹

        Returns:
            å„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®è¾æ›¸
        """
        logger.info("="*80)
        logger.info("ORATNEK SCREENER - Running All Screens")
        logger.info("="*80)

        start_time = datetime.now()

        if use_multiprocessing:
            logger.info(f"Using multiprocessing with {MAX_WORKERS} workers...")
            results = self._run_screens_parallel()
        else:
            logger.info("Running screens sequentially...")
            results = {
                'momentum_97': self.screen_momentum_97(),
                'explosive_eps': self.screen_explosive_eps_growth(),
                'up_on_volume': self.screen_up_on_volume(),
                'top_2_rs': self.screen_top_2_percent_rs(),
                'bullish_4pct': self.screen_4_percent_bullish_yesterday(),
                'healthy_chart': self.screen_healthy_chart_watchlist(),
            }

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("="*80)
        logger.info("SCREENING SUMMARY")
        logger.info("="*80)
        for name, df in results.items():
            logger.info(f"{name:25s}: {len(df):3d} stocks")
        logger.info(f"\nTotal execution time: {duration:.2f} seconds")
        logger.info("="*80)

        # çµæœã‚’ä¿å­˜
        self._save_results(results, duration)

        return results

    def _run_screens_parallel(self) -> Dict[str, pd.DataFrame]:
        """
        ä¸¦åˆ—å‡¦ç†ã§å…¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ

        Returns:
            å„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®è¾æ›¸
        """
        # ã¾ãšå…¨éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒå‡¦ç†ã§èª­ã¿è¾¼ã¿
        logger.info(f"Preloading data for {len(self.tickers)} tickers...")
        self._preload_data_parallel()

        # å„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        results = {
            'momentum_97': self.screen_momentum_97(),
            'explosive_eps': self.screen_explosive_eps_growth(),
            'up_on_volume': self.screen_up_on_volume(),
            'top_2_rs': self.screen_top_2_percent_rs(),
            'bullish_4pct': self.screen_4_percent_bullish_yesterday(),
            'healthy_chart': self.screen_healthy_chart_watchlist(),
        }

        return results

    def _preload_data_parallel(self):
        """
        ä¸¦åˆ—å‡¦ç†ã§å…¨éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰èª­ã¿è¾¼ã¿

        HWBã®è¨­è¨ˆã‚’å‚è€ƒã«ã€ãƒãƒƒãƒå‡¦ç†ã¨ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã‚’ä½¿ç”¨
        """
        total = len(self.tickers)

        # å…¨ä½“ã®é€²æ—ãƒãƒ¼
        with tqdm(total=total, desc="ğŸ“Š Preloading data", unit="ticker") as pbar:
            for i in range(0, total, BATCH_SIZE):
                batch = self.tickers[i:i + BATCH_SIZE]
                batch_num = i//BATCH_SIZE + 1
                total_batches = (total + BATCH_SIZE - 1)//BATCH_SIZE

                pbar.set_description(f"ğŸ“Š Batch {batch_num}/{total_batches}")

                with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                    future_to_ticker = {
                        executor.submit(self._get_stock_data, ticker): ticker
                        for ticker in batch
                    }

                    for future in concurrent.futures.as_completed(future_to_ticker):
                        ticker = future_to_ticker[future]
                        try:
                            result = future.result()
                            if result:
                                pbar.set_postfix_str(f"âœ“ {ticker}")
                            else:
                                pbar.set_postfix_str(f"âœ— {ticker} (no data)")
                        except Exception as exc:
                            pbar.set_postfix_str(f"âœ— {ticker} (error)")
                            logger.error(f"{ticker}: Error - {exc}")
                        finally:
                            pbar.update(1)

        logger.info(f"âœ“ Data preloading completed. Cached {len(self.data_cache)} tickers.")

    def _save_results(self, results: Dict[str, pd.DataFrame], duration: float):
        """
        ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ä¿å­˜

        Args:
            results: ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ
            duration: å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        """
        try:
            summary = {
                'scan_date': datetime.now().strftime('%Y-%m-%d'),
                'scan_time': datetime.now().strftime('%H:%M:%S'),
                'scan_duration_seconds': duration,
                'total_tickers': len(self.tickers),
                'summary': {
                    name: {
                        'count': len(df),
                        'tickers': df['ticker'].tolist() if 'ticker' in df.columns else []
                    }
                    for name, df in results.items()
                }
            }

            self.data_manager.save_screening_results(summary)

            # å„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’CSVã«ä¿å­˜
            for name, df in results.items():
                if not df.empty:
                    csv_filename = f"screener_{name}_{datetime.now().strftime('%Y%m%d')}.csv"
                    csv_path = self.data_manager.results_dir / csv_filename
                    df.to_csv(csv_path, index=False)
                    logger.info(f"Saved {name} to {csv_path}")

        except Exception as e:
            logger.error(f"Failed to save results: {e}", exc_info=True)


def get_default_tickers() -> List[str]:
    """
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—

    Returns:
        éŠ˜æŸ„ãƒªã‚¹ãƒˆ
    """
    # S&P 100ä¸»è¦éŠ˜æŸ„ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
    return [
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'BRK-B',
        'UNH', 'XOM', 'JNJ', 'JPM', 'V', 'PG', 'MA', 'HD', 'CVX', 'MRK',
        'ABBV', 'PEP', 'KO', 'AVGO', 'COST', 'MCD', 'TMO', 'WMT', 'CSCO',
        'ABT', 'DHR', 'ACN', 'VZ', 'CMCSA', 'ADBE', 'NKE', 'TXN', 'NEE',
        'PM', 'UNP', 'CRM', 'RTX', 'LOW', 'HON', 'ORCL', 'QCOM', 'UPS',
        'AMD', 'INTC', 'IBM', 'NFLX', 'BA', 'GE', 'CAT', 'SBUX', 'AMGN',
        'NOW', 'SPGI', 'GS', 'AXP', 'BLK', 'MDT', 'ISRG', 'DE', 'TGT',
        'CI', 'GILD', 'CVS', 'SYK', 'MO', 'MMM', 'ZTS', 'DUK', 'PLD',
        'SO', 'ITW', 'CB', 'BSX', 'EQIX', 'APD', 'SHW', 'CL', 'CME',
        'USB', 'PNC', 'SCHW', 'EOG', 'NOC', 'MMC', 'AON', 'TJX', 'ICE',
    ]


def run_oratnek_screener(
    tickers: Optional[List[str]] = None,
    use_multiprocessing: bool = True,
    data_manager: Optional[OratnekDataManager] = None
) -> Dict[str, pd.DataFrame]:
    """
    Oratnekã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã‚’å®Ÿè¡Œ

    Args:
        tickers: å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŠ˜æŸ„ï¼‰
        use_multiprocessing: ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        data_manager: ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆNoneã®å ´åˆã¯æ–°è¦ä½œæˆï¼‰

    Returns:
        ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®è¾æ›¸
    """
    if tickers is None:
        tickers = get_default_tickers()

    logger.info(f"Starting Oratnek Screener with {len(tickers)} tickers...")

    screener = OratnekScreener(tickers, data_manager)
    results = screener.run_all_screens(use_multiprocessing=use_multiprocessing)

    return results


if __name__ == '__main__':
    """
    ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    """
    import sys

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹åŒ–ã‚’åˆ¶å¾¡
    use_mp = '--no-mp' not in sys.argv

    logger.info("="*80)
    logger.info("ORATNEK SCREENER - Standalone Test")
    logger.info(f"Multiprocessing: {'Enabled' if use_mp else 'Disabled'}")
    logger.info("="*80)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŠ˜æŸ„ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    results = run_oratnek_screener(use_multiprocessing=use_mp)

    logger.info("\nScreening completed successfully!")
